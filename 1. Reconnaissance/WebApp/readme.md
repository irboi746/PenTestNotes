# WebApp Recon
## Passive Recon
* The first step of Web information Gathering usually starts from electronic footprint of the target's websites, network and employees. As we know, these information can be gathered using passive recon methods.

### Tools of the trade : 
   1. WHOIS
      * used to look up domain ownership details from different databases
      * can be CLI or web-based (whois.domaintools.com)
      * typically runs on TCP port 43
      
      |Yield| | |
      |-----|-|-|
      |IP Address|admin contact info|technical contact info|
       
   2. NSLOOKUP (DNS ENUMERATION) 
      * DNS can be queried for IP addresses that we gathered from WHOIS database.
      * Remember RR types :
      
       | TYPE | Values and Meaning |
       |------|--------------------|
       |A|host IP address|
       |NS|an authoritative name server|
       |SOA| marks the start of a zone of authority|
       |CNAME|the canonical name for an alias|
       |MX|mail exchange|
       |PTR|Domain Name Pointer|
      
      * Command to run : `nslookup -querytype=ANY <domain name>`
      * The above command will run a nslookup on any of the RR Types listed in the table above.
      * nslookup might reveal more IP addresses, where there will be a need to recursively query the IP address with WHOIS to find out more information about the target.  
      
      |Yield| | |
      |-----|-|-|
      |IP Address|Netblock|owner of netblock(recursive whois query)|
      
   3. Netcraft (www.netcraft.com)
      * One Stop Recursive DNS and WHOIS Enumeration 
      
      |Yield| | |
      |-----|-|-|
      |IP Address of domain|Netblock|owner of netblock(recursive whois query)|
      
* **Aim of recursive WHOIS and NSLOOKUP is to uncover all IP addresses related to the domain or subdomain of the target.**
4. OSINT
      * Linkedin
      * Job Postings
      * Partners & Third Parties 
5. Google Hacking
   * Means to use Google's sophisticated search operators to uncover misconfigured web servers, sensitive informaiton left on a server, password files, etc.
   * [Google Hacking DB](https://www.exploit-db.com/google-hacking-database) contains a list of searches for many purposes.
6. Shodan
   * Another search engine that scans the entire internet and interrogates ports in order to gather information from banners.
   * Searches in HTTP(S), RDP, SSH, SNMP, FTP, Telnet, MySQL, MongoDB protocols.
   * Used to search for device with default username and password, viewing configuration of devices, detect server versions etc.
   
## Active Recon
* At this stage, we will be mounting scans and commands directly to the server and making our recon more visible.
* Typically, subdomain enumeration and webserver fingerprinting will give us an overview of the infrastructure as a whole.

### Subdomain Enumeration
* mapping of all available subdomains within a domain name to widen attack surface and sometimes reveal hidden management panels or intranet web applications.

#### Tools of the Trade : 
1. subbrute
   * uses a default wordlist to find subdomains of a specific target.
   * useful for internal pentest
   * Command used : `python subbrute.py <options> <target>`

2. dnsrecon
   * similar to subbrute but also able to leverage on search engines like google.
   * Command used : `dnsrecon -d <target>`
  
3. theHarvester
   * tool for gathering subdomain names from different public sources such as search engines or PGP key servers.

4. NSLOOKUP (zone transfer)
   * Zone Transfer refers to the process by which the contents of a DNS Zone File are copied from a primary DNS server to a secondary DNS server.
   * Usually a misconfiguration of the remote DNS server. (should only be enabled for trusted IP address)
   * when Zone Transfers are available, we can enumerate all the DNS records for that zone. 
   * Command used
     * (Windows) 
     
     ```
      step 1 : to find out the nameservers
      nslookup -type=NS example.com  
      
      Step 2 : to find out zone transfers
      nslookup --> new instance of nslookup
      server ns.example.com
     ```
     
     * (Linux) `dig @ns.example.com axfr example.com`
   
##### Web Tools : 
1. Netcraft
2. Google
   * using the `site:` or `inurl: `
### Virtual Hosts
* In a shared hosting environment, a website shares IP address with on or more virtual hosts.
* Hence many domains and subdomains can share the same IP address.
#### Tools of the Trade
1. Fierce
   * Tools like fierce is able to do subdomain enumeration but display results of enumeration with domain name and IP address. 

### Fingerprint Webserver and Frameworks 
* WebServer Fingerprinting can be useful not just for WebApp attack but also for attacking the OS (vulnerabilities based on OS version) hence information here might have overlap with OS attacks.
* ISAPI Extensions (a component of IIS) and web application firewall can affect the results of fingerprinting.
   * An example of such ISAPI Extensions/htaccess/mod_rewrite rules are SEF(Search Engine Friendly) URLs where URL such as `www.example.com/read.php?id=10` is transformed into `www.example.com/read/example.html` 
   * Only URL parameter attacks are affected;forms, cookies and header attacks are still possible.
* Fingerprinting Frameworks and Applications 
#### Tools of the Trade : 
1. netcat
   * netcat is a networking utility for reading and writing to TCP or UDP network connections. 
   * We can make use of netcat to investigate the HTTP **RESPONSE** by sending a request 
   * Commands to use : 
   ```
   nc <ip address> <port>
   HEAD / HTTP/1.0
   ```
   * Typical Response  
   ![nc1](https://github.com/irboi746/PenTestNotes/blob/main/1.%20Reconnaissance/WebApp/Resources/netcat1.JPG)
   ![nc2](https://github.com/irboi746/PenTestNotes/blob/main/1.%20Reconnaissance/WebApp/Resources/netcat2.JPG)
   * Obfuscated Response \
   ![nc3](https://github.com/irboi746/PenTestNotes/blob/main/1.%20Reconnaissance/WebApp/Resources/netcat3.JPG)
   * [Testing for Web Application Fingerprint (OWASP-IG-004)](https://wiki.owasp.org/index.php/Testing_for_Web_Application_Fingerprint_(OWASP-IG-004)#Protocol_behaviour) also entails the other indicators to identify OS version and server technology like ***HTTP Header Field Order***, ***Malformed Request Test***.
   
   |Yield| |
   |-----|-|
   |Server OS|Server Technology|

2. Web cookies
   * Web cookies can also be sources of information that reveal the server technology used
   * Each technology has their own default cookie names and it is usually left as default.
   
   |Server|Cookie|
   |------|------|
   |PHP|PHPSESSID=xxx|
   |.NET|ASPSSESSIONIDYYYY=XXXX|
   |JAVA|JSESSION=XXXX|

3. whatweb
   * a commandline tool that is available in Kali. 
   * Command used `whatweb <URL/IP ADDRESS> -v`
   * -v option helps format the information to be more readable
   ![whatweb](https://github.com/irboi746/PenTestNotes/blob/main/1.%20Reconnaissance/WebApp/Resources/whatweb.png)
4. wappalyzer
   * it is a **firefox** / **chrome** browser plugin that reveals the technologies used by the web application.
   ![wapplyzer](https://github.com/irboi746/PenTestNotes/blob/main/1.%20Reconnaissance/WebApp/Resources/wapplyzer.JPG)

5. Burp Suite

##### Web Tools : 
1. Netcraft 
   * not useful if webapp is an internal server or there might be times where netcraft is unable to get the required information.

   |Yield| | |
   |-----|-|-|
   |Web Server Version|IP addresses|Nameservers|
   |Uptime Stats|IP Address Owner|Host Provider|

### Enumerating Applications
* Concept is to find out what the application does and how it does it.
* It is common to have COTS application with custom codes and hence the below scope 

|Scope | | |
|What is Application For | Is user registration allowed? | Are there any Admin panel|
|does it take input from user? |what are the inputs taken? |does it accept file uploads? |
|Is javascript, ajax, flash used?| | |

#### Tools of the Trade
1. Burp Suite
   * Using Burp Proxy Spider to collect and analyse all headers and responses.
   * We can enumerate by trying out all the subdomains and functions with burp recording.
   * Tips on analysis : 
      1. Use a web browser to study target behaviour 
          * identify the main functions of the website (e-commerce, blog, forum, admin panel login, member login etc.)
          * Draw a functional graph to map out the function blocks, using shapes to signify different functions
          * This will help us visualise the application better and a basis for further testing.
    
    |Square|Rhombus|Oval|Hexagon|
    |------|-------|----|-------|
    |Function|Function with login page|Main page|core function|

      2. Investigate each blocks in more details
         * Use arrows to signify login protection for blocks e.g login page --> download page
         * Shape of block will change with new knowledge of page (application found)
         * Look out for : client side logic(javascript codes), flash applications, cookies, authorisation, forms etc.
      ![sample_functionalgraph](https://github.com/irboi746/PenTestNotes/blob/main/1.%20Reconnaissance/WebApp/Resources/functional%20graph.png)  


###  Enumerating Other Resources
* Apart from subdomains we can also enumerate the website for hidden files(config, backup)

#### Tools of the Trade : 
1. Burp Suite
   * Using Burp to do an exhaustive automatic crawl of website.
2. DirBuster
   * used to enumerate directories and files using a dictionary or brute force regex
3. robots.txt 
   * a config file that tells search engine crawlers which URLs the crawler can access on your site. 

### Information Disclosure through Misconfiguration
* Looking through misconfigured directory listings for interesting files
   * Lookout for log files, config files, backup files
   * check if uploading of files is even possible using PUT verb.

#### Tools of the Trade
1. Netcat
Command used : 
   1. To check for VERBS : `OPTIONS / HTTP/1.1`
   2. Manually test VERBS : 
   ```
   PUT /test.html HTTP/1.1
   Content-length : 10
   <content of test.html>
   ```
      * expected response for successful PUT ---> HTTP 201
   
### Mapping Attack Surface to Information Gathered
* attack surfaces above can be mapped according to information gathered : 

|Attack Surface|Expalnation|
|--------------|-----------|
|Client Side Validation|inspecting web page source and looking for interesting javascript functions|
|Database Interaction|determine how user input changes appearance of page which can lead to SQLi|
|File Upload and Download|web pages that provide dynamic downloads based on user provided parameters which can lead to Local or Remote File Inclusion Attack or any uploads misconfiguration that can lead to reverse web shell|
|Display of User supplied Data|unintentional display of user data which can lead to XSS|
|Redirections|meta redirect vs 301/302 redirect are examples of Client side or Server side redirect respectively which can lead to HTTP reponse splitting or Header manipulation attacks when misconfigured |
|Access control and Login Protected Pages|reveals the presence of restricted access, where authentication bypass can be done|
|Error Messages|unintentional error messages that can be leveraged|

* Functional graph and attack surface can then be combined as a table like below : 

|Blocks|Client Side validation|Redirection|...|
|------|----------------------|-----------|---|
|Blog|No|Yes|...|
|ecommerce|yes|yes|...|
|...|...|...|...|



